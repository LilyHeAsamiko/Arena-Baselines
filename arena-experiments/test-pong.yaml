# On a single GPU, this achieves maximum reward in ~15-20 minutes.
#
# $ python train.py -f tuned_examples/pong-ppo.yaml
#
test-pong:
    env: PongNoFrameskip-v4
    run: PPO
    checkpoint_freq: 20
    checkpoint_at_end: True
    config:
        # === Environment Settings ===
        clip_rewards: True
        # === Settings for Rollout Worker processes ===
        num_workers: 10
        num_envs_per_worker: 2
        sample_batch_size: 100
        batch_mode: truncate_episodes
        observation_filter: NoFilter
        # === Settings for the Trainer process ===
        num_gpus: 1
        train_batch_size: 5000
        # === PPO Settings ===
        lambda: 0.95
        kl_coeff: 0.5
        clip_param: 0.1
        vf_clip_param: 10.0
        entropy_coeff: 0.01
        sgd_minibatch_size: 500
        num_sgd_iter: 10
        vf_share_layers: True
        # === Debug Settings ===
        "monitor": False
